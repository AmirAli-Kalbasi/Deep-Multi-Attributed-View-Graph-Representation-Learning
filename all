import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
import numpy as np
import random
from sklearn.metrics import average_precision_score, roc_auc_score, f1_score

def load_dataset(name):
    """
    Load a dataset from the PyTorch Geometric library.

    Args:
        name (str): The name of the dataset.

    Returns:
        GM (dict): A dictionary containing the following attributes:

            * A: The adjacency matrix of the graph.
            * x: The node features.
            * y: The node labels.
    """


    if name == 'cora':
        GM = Planetoid('cora')
        n_nodes, n_edges, n_views, n_labels = 2607, 5429, 3, 7
    elif name == 'citeseer':
        GM = Planetoid('citeseer')
        n_nodes, n_edges, n_views, n_labels = 3312, 4660, 3, 6
    elif name == 'epinions':
        GM = Planetoid('epinions')
        n_nodes, n_edges, n_views, n_labels = 36497, 215043, 3, 28
    elif name == 'ciao':
        GM = Planetoid('ciao')
        n_nodes, n_edges, n_views, n_labels = 10948, 99038, 3, 67
    else:
        raise ValueError('Invalid dataset name: {}'.format(name))

    print("Statistics of {}: # Nodes: {}, # Edges: {}, # Views: {}, # Label: {}".format(name, n_nodes, n_edges, n_views, n_labels))

    return GM, n_nodes, n_edges, n_views, n_labels



class MagCAE(nn.Module):
    def __init__(self, n_views, n_nodes, n_latent_dim):
        super(MagCAE, self).__init__()
        # ...
    
    def forward(self, X):
        # Normalize adjacency matrix
        A_tilde = F.normalize(X['A'], p=1, dim=1)

        # Compute single-attributed-view proximity Sma for each view m
        Sma = []
        for m in range(self.n_views):
            X_m = X['X'][:, :, m]
            gamma_m = X['gamma'][m]
            X_diff = (X_m.unsqueeze(1) - X_m.unsqueeze(2)).norm(dim=3)
            Sma.append(torch.exp(-gamma_m * X_diff.unsqueeze(2)))

        # Initialize GCN embeddings Z0m to node features Xm and weight on Z0m to w0m
        Z0m = [X['X'][:, :, m] for m in range(self.n_views)]
        W0m = [nn.Parameter(torch.ones(self.n_nodes)) for _ in range(self.n_views)]

        # Compute multi-attributed-view proximity Sv
        Sv = torch.prod(torch.stack(Sma), dim=0)

        # Train model using gradient descent
        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)

        while True:
            optimizer.zero_grad()

            # Update GCN variables Wtm and embeddings Ztm for each single-attributed-view m
            for m in range(self.n_views):
                Wtm = F.softmax(W0m[m], dim=0)
                Ztm = F.relu(self.gcn_layers[m][0](torch.sparse.mm(A_tilde, Z0m[m])) + self.gcn_layers[m][1](Z0m[m]))
                Z0m[m] = Ztm
                W0m[m] = Wtm

            # Update multi-attributed view weights wt by Eq. (11)
            wt = F.softmax(self.weights, dim=0)

            # Update aggregate embeddings Zt by Eq. (2)
            Zt = torch.cat([wt[i] * Z0m[i] for i in range(self.n_views)], dim=1)
            Zt = F.relu(self.final_layer(Zt))

            # Update reconstructed adjacency matrix A′t by Eq. (3)
            A_prime_t = torch.sigmoid(self.reconstruction_layer(Zt)).view(-1, self.n_nodes, self.n_nodes)

            # Update reconstruction loss between A and A′t by Eq. (8)
            L_res_t = F.binary_cross_entropy(A_prime_t.view(-1), X['A'].view(-1))

            # Update embedding proximity Ste by Eq. (6)
            Ste_t = torch.exp(-torch.norm(Zt.unsqueeze(1) - Zt.unsqueeze(2), dim=3) / self.n_latent_dim)

            # Update node-pairwise similarity loss between Sv and Ste by Eq. (9)
            L_sim_t = torch.abs(Sv - Ste_t).sum() / (self.n_nodes ** 2)

            # Update total loss Lt by Eq. (7)
            L_t = L_res_t + L_sim_t

            # Stop training if loss is below threshold
            if L_t < 0.01:
                break

            # Backpropagate gradients
            L_t.backward()

            # Update weights
            optimizer.step()

        return Zt


    def predict(self, edges):
        """Generate scores for a given set of edges.

        Args:
            edges (np.array): A numpy array of shape (num_edges, 2) representing the edges to be scored.

        Returns:
            scores (np.array): A numpy array of shape (num_edges,) representing the scores for each edge.
        """
        with torch.no_grad():
            # Normalize adjacency matrix
            A_tilde = F.normalize(self.X['A'], p=1, dim=1)

            # Compute single-attributed-view proximity Sma for each view m
            Sma = []

            for m in range(self.n_views):
                Sma.append(torch.exp(-self.X['gamma'][m] * torch.norm(self.X['X'][:, :, m].unsqueeze(1) - self.X['X'][:, :, m].unsqueeze(2), dim=3)))
        
            # Initialize GCN embeddings Z0m to node features Xm and weight on Z0m to w0m
            Z0m = [self.X['X'][:, :, m] for m in range(self.n_views)]
            W0m = [nn.Parameter(torch.ones(self.n_nodes)) for _ in range(self.n_views)]
        
            # Compute multi-attributed-view proximity Sv
            Sv = torch.prod(torch.stack(Sma), dim=0)
            
            # Update GCN variables Wtm and embeddings Ztm for each single-attributed-view m
            for m in range(self.n_views):
                Wtm = F.softmax(W0m[m], dim=0)
                Ztm = F.relu(self.gcn_layers[m][0](torch.sparse.mm(A_tilde, Z0m[m])) + self.gcn_layers[m][1](Z0m[m]))
                Z0m[m] = Ztm
                W0m[m] = Wtm
        
            # Update multi-attributed view weights wt by Eq. (11)
            wt = F.softmax(self.weights, dim=0)
                    
            # Update aggregate embeddings Zt by Eq. (2)
            Zt = torch.cat([wt[i] * Z0m[i] for i in range(self.n_views)], dim=1)
            Zt = F.relu(self.final_layer(Zt))
        
            # Compute scores for the input edges
            src_embeds = Zt[edges[:, 0]]
            dst_embeds = Zt[edges[:, 1]]
            scores = torch.sum(src_embeds * dst_embeds, dim=1).numpy()
        
            return scores





# Define hyperparameters and instantiate the model
#n_nodes = 100
#n_latent_dim = 16
#model = MagCAE(n_views=n_views, n_nodes=n_nodes, n_latent_dim=n_latent_dim)

# Load a dataset (example: 'cora')
dataset_name = 'cora'
dataset, n_nodes, n_edges, n_views, n_labels = load_dataset(dataset_name)

# Split the dataset into training, validation, and testing sets
train_edges = dataset['train_pos_edge_index'].T.numpy()
val_edges = dataset['val_pos_edge_index'].T.numpy()
test_edges = dataset['test_pos_edge_index'].T.numpy()
num_nodes = dataset['x'].shape[0]

# Generate negative samples for validation and testing sets
val_neg_edges = np.stack([np.random.choice(num_nodes, 2, replace=False) for _ in range(val_edges.shape[0])])
val_all_edges = np.vstack([val_edges, val_neg_edges])
val_labels = np.hstack([np.ones(val_edges.shape[0]), np.zeros(val_neg_edges.shape[0])])

test_neg_edges = np.stack([np.random.choice(num_nodes, 2, replace=False) for _ in range(test_edges.shape[0])])
test_all_edges = np.vstack([test_edges, test_neg_edges])
test_labels = np.hstack([np.ones(test_edges.shape[0]), np.zeros(test_neg_edges.shape[0])])

# Train the model
Zt = MagCAE(dataset)

# Evaluate the link prediction results using AP and AUC
val_scores = MagCAE.predict(val_all_edges)
val_ap = average_precision_score(val_labels, val_scores)
val_auc = roc_auc_score(val_labels, val_scores)

test_scores = MagCAE.predict(test_all_edges)
test_ap = average_precision_score(test_labels, test_scores)
test_auc = roc_auc_score(test_labels, test_scores)

# Evaluate the node classification performance using Micro-F1 and Macro-F1 scores
f1_scores = []
for i in range(10):
    # Split the nodes into training and testing sets
    train_nodes = np.random.choice(num_nodes, int(num_nodes * 0.8), replace=False)
    test_nodes = np.setdiff1d(np.arange(num_nodes), train_nodes)

    # Get the true and predicted labels for the test nodes
    true_labels = dataset['y'][test_nodes].numpy()
    pred_labels = MagCAE.predict(dataset)[test_nodes].numpy()

    f1_scores.append(f1_score(true_labels, pred_labels, average='micro'))
    f1_scores.append(f1_score(true_labels, pred_labels, average='macro'))

print('Validation AP: {:.4f}'.format(val_ap))
print('Validation AUC: {:.4f}'.format(val_auc))
print('Testing AP: {:.4f}'.format(test_ap))
print('Testing AUC: {:.4f}'.format(test_auc))
print('Micro-F1: {:.4f}'.format(np.mean(f1_scores[::2])))
print('Macro-F1: {:.4f}'.format(np.mean(f1_scores[1::2])))



###
import matplotlib.pyplot as plt

# Hyperparameters for the experiments
hidden_dims = [4, 8, 16, 32, 64]
n_views = 3
n_latent_dim = 16

# Load a dataset (example: 'cora')
dataset_name = 'cora'
dataset, _, _, _, _ = load_dataset(dataset_name)

# Split the dataset into training, validation, and testing sets
train_edges = dataset['train_pos_edge_index'].T.numpy()
val_edges = dataset['val_pos_edge_index'].T.numpy()
test_edges = dataset['test_pos_edge_index'].T.numpy()
num_nodes = dataset['x'].shape[0]

# Generate negative samples for validation and testing sets
val_neg_edges = np.stack([np.random.choice(num_nodes, 2, replace=False) for _ in range(val_edges.shape[0])])
val_all_edges = np.vstack([val_edges, val_neg_edges])
val_labels = np.hstack([np.ones(val_edges.shape[0]), np.zeros(val_neg_edges.shape[0])])

test_neg_edges = np.stack([np.random.choice(num_nodes, 2, replace=False) for _ in range(test_edges.shape[0])])
test_all_edges = np.vstack([test_edges, test_neg_edges])
test_labels = np.hstack([np.ones(test_edges.shape[0]), np.zeros(test_neg_edges.shape[0])])

# Train the model with varying hidden layer dimensions
aps = []
aucs = []

for hd in hidden_dims:
    print('Running experiment with hidden dimension: ', hd)
    model = MagCAE(n_views=n_views, n_nodes=num_nodes, n_latent_dim=n_latent_dim, hidden_dim=hd)

    # Train the model
    Zt = model(dataset)

    # Evaluate the link prediction results using AP and AUC
    val_scores = model.predict(val_all_edges)
    val_ap = average_precision_score(val_labels, val_scores)
    val_auc = roc_auc_score(val_labels, val_scores)

    test_scores = model.predict(test_all_edges)
    test_ap = average_precision_score(test_labels, test_scores)
    test_auc = roc_auc_score(test_labels, test_scores)

    aps.append(test_ap)
    aucs.append(test_auc)

# Plot the results
fig, ax = plt.subplots()
ax.plot(hidden_dims, aps, label='AP')
ax.plot(hidden_dims, aucs, label='AUC')
ax.legend()
ax.set_xlabel('GCN hidden layer dimension')
ax.set_ylabel('Link prediction performance')
ax.set_title('GCN hidden layer dimension vs. Link prediction performance')

plt.show()
